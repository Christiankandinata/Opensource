services:
    pgdatabase:
        image: postgres:13
        environment:
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=root
            - POSTGRES_DB=ny_taxi
        volumes:
            - "./ny_taxi_postgres_data:/var/lib/postgresql/data:rw"
        ports:
            - "5432:5432"
        networks:
            - airflow
    # pgadmin:
    #     image: dpage/pgadmin4
    #     environment:
    #         -  PGADMIN_DEFAULT_EMAIL=admin@admin.com
    #         -  PGADMIN_DEFAULT_PASSWORD=root
    #     ports:
    #         - "8080:80"

networks:
    airflow:
        external:
            name: airflow_default

# winpty docker run -it \
#     -e POSTGRES_USER= "postgres" \
#     -e POSTGRES_PASSWORD= "root" \
#     -e POSTGRES_DB= "ny_taxi" \
#     -v C:/Users/Christian Kandinata/Documents/Github/Opensource/Data-Engineering/Week1/3_docker_sql/ny_taxi_postgres_data:/var/lib/postgresql/data \
#     -p 5432:5432 \
#     postgres:13

# winpty docker run -it b -e POSTGRES_USER= "root" -e POSTGRES_PASSWORD= "root" -e POSTGRES_DB= "ny_taxi" -v c:/Users/JULO/Opensource/Data-Engineering/Week1/3_docker_sql/ny_taxi_postgres_data:/var/lib/postgresql/data -p 5432:5432 postgres:13


# Running Docker for Postgresql
# -> winpty docker run -it -p 5432:5432 -e POSTGRES_USER="postgres" -e POSTGRES_PASSWORD="root" -e POSTGRES_DB="ny_taxi" postgres:14

# Running pgcli in bash environment
# -> winpty pgcli -h localhost -p 5432 -u postgres -d ny_taxi

# To download data from amazons3 using wget in bash environment
# -> wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2021-01.csv --no-check-certificate

# Checking top 100 rows for the success csv files downloaded and export it into new file (yellow_head.csv)
# -> head -n 100 yellow_tripdata_2021-01.csv > yellow_head.csv

# Checkin how many rows in one csv files
# -> wc -l yellow_tripdata_2021-01.csv